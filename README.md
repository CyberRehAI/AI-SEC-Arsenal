# AI-SEC-Arsenal
AI Security Portfolio | Red Teaming LLMs, Agents, RAG &amp; MCP | Jailbreaks, Prompt Injection, Adversarial ML

# AI-Sec-Arsenal

My public portfolio as an aspiring **AI Security Specialist** (red teaming LLMs, agents, RAG, MCP, adversarial ML).  
Currently in Phase 1 of my 2025–2027 roadmap: building hands-on projects to master LLM jailbreaks, prompt injection, and defenses.

## Current Projects
- **Project 1: LLM Jailbreak Defense Suite**  
  Interactive Streamlit app demonstrating 15+ jailbreak techniques (DAN, encoding, multi-turn, CoT manipulation, etc.) with mitigation layers and metrics dashboard.  
  Goal: 85%+ attack success pre-mitigation → <5% post-mitigation.  
  [Live Demo ](https://ai-sec-arsenal-nfx3dylsawsaepym8qs8hc.streamlit.app) | [Code → projects/project1-llm-jailbreak-suite](projects/project1-llm-jailbreak-suite)

- **Project 2: Adversarial ML Attack Simulator** (in progress)  
  Jupyter notebook with FGSM/PGD evasion attacks on MNIST/CIFAR-10 + defenses.

## Journey & Roadmap
Following a structured 2025(late)–2027 plan focused on AI red teaming and cloud AI security.  
Weekly updates, attack demos, mitigation proofs, and metrics.  
Inspired by OWASP LLM Top 10, Garak, DeepTeam, and recent CTFs (e.g., Lakera Agent Breaker).

## Tech Stack (Phase 1)
- Python, Streamlit, OpenAI/Anthropic APIs  
- Tools: Garak, Foolbox (upcoming)

## Connect
- LinkedIn: To be Added
- Email: dev.abd04@gmail.com

Star ⭐ if you're into AI security red teaming!
